---
title: "Best Seasonality Decomposition"
author: "Tianyang Xie"
date: "`05/04/2019`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction
Time series analysis is one of the most popular topics in statistics. The application of time series analysis techniques have been employed to many other fields of study such as finance (stock price prediction, risk management), economics (gdp prediction, causality inference) etc.

Domain knowledge of many fields, especially in social science, will assume the time series are generated by long-term information (trend, seasonality) and short-term impact. Thus, for the analysis of an univariate time series, the original data sequence is often decomposed into trend, seasonality, and a short-term random sequence.

\begin{equation}
X(t) = Trend(t) + Seasonality(t) + Random(t) \notag
\end{equation}

1. X(t): Original data sequence.
2. Trend(t): Usually smooth, monotone function of t. .
3. Seasonality(t): Function of t. Has periods. 
4. Random(t): Short term deviation. Needs model.

In classical setting, we tend to do the following:
1. Fit X~t to get linear trend.
2. Specify the period for seasonality, take sample mean of X refers to periods.
3. Leave random effect along. (Or pretend to fit with a simple model)

After splitting out trend (e.g. linear trend), let's focus on decomposition of seasonality and random terms. Utilize merit of ARMA, we expand the model as:
\begin{align}
X_t = \sum_{i=1}^p \phi_i X_{t-i}&  + \sum_{i=1}^q \psi_i \epsilon_{t-i} + \sum_{i=1}^{r} \tau_i X_{t-s_i} + \epsilon_t \notag\\
\text{where } \epsilon_t &\sim N(0,\sigma^2) \notag\\
M &= \{p,q,r,S\} \notag\\
\Theta|M &= \{\phi_{1:p},\psi_{1:q},\tau_{1:r},\sigma^2\} \notag
\end{align}

Our goal is to:
1. Optimize M to accommodate seasonality and random effect at the same time.
2. Estimate $\Theta$.
3. Input: Range of p, range of q, range of S, range of the number of periods. Output: A best      seasonal ARMA model with optimal prediction power.
4. Most importantly: Beat Prophet, the Facebook data science team product!

## Method
We aim to choose the best seasonality terms along with ARMA terms. The range of seasonality could be to large to start with, thus we need to shrink the range before we employ model selection or bayesian inference. This is achieved by spectral analysis technique.
Any stationary univariate time series can be transformed as:
\begin{align}
X_t = \sum U_{\omega} sin(\frac{\pi t}{\omega}) + V_{\omega} cos(\frac{\pi t}{\omega}) \notag \\
U_{\omega}, \sim N(0,\sigma_{1,\omega}^2) \notag \\
V_{\omega}, \sim N(0,\sigma_{2,\omega}^2) \notag
\end{align}

Then we try each dimension parameter M. Estimate coefficients $\Theta|M$ by MLE, using Gauss-Newton algorithm (BFGS). Select the best model $\tilde M$ with lowest AIC. 

## Computation
The package utilize optim() function majorly to compute coeffcients estimations. BFGS, one of the most popular quasi-Newton algorithm is being employed. Rcpp and RcppArmadillo dependencies are used for computing likelihood, fitted values, and gradient. 

## Examples
The first example is the classical toy example for seasonal univariate time series. 
```{r,fig.height = 6, fig.width = 6}
library(tsms)

data(AirPassengers)
air = as.matrix(AirPassengers)

t = c(1:nrow(air))
m = lm(air~I(t^1.5))
trend = as.matrix(fitted.values(m))
X = air - trend

# 1.FSARMA.fit: Fit model by specifyied parameters
U = 14
p = 4
q = 1
S = c(12)
obj = FSARMA.fit(as.matrix(X[1:100,1]),U,p,q,S)

# 2.FSARMA.select: Fit multiple models and select by aic
p_range = c(0:5)
q_range = c(0:3)
S_range = c(6,8,10,12)
r_range = c(1,2)
obj = FSARMA.select(as.matrix(X[1:100,1]),U,p_range,q_range,r_range,S_range)

# 3.FSARMA.predict: Prediction
prediction = FSARMA.pred(obj[[1]],as.matrix(X[1:100]),50)

# 4.FSARMA.auto: fit & select & predict in all (S_range is automatically suggestted)
result = FSARMA.auto(as.matrix(X[1:100,1]),U,pred_t=50,p_range,q_range,r_range,S_range=NULL,k=2,width=5,level=0.05,specplot=TRUE)
prediction = result$prediction

plot(X,type='l',main='Airpassenger')
abline(v=100)
lines(prediction,col='red')
```

We train the model on 100 observations, and predict on the rest of time. The result is undoubtly good. Let's have a look at a more complicated example. This is the data that is using as example for Facebook Prophet.

```{r,fig.height = 6, fig.width = 6}
library(prophet)

# Data preparation
prop = read.csv('../examples/example_wp_log_peyton_manning.txt',header=TRUE)
m = prophet(prop[1:2540,])
future = make_future_dataframe(m, periods = 365)
forecast = predict(m, future)
X = as.matrix(prop$y)

# Train the model
U = 600
p_range = c(10:15)
q_range = c(5:10)
r_range = c(1:3)
result = FSARMA.auto(X[1:2540,1,drop=F],U,pred_t=365,p_range,q_range,r_range,S_range=NULL,k=2,
                     width=5,level=0.05,specplot=TRUE)
prediction = result$prediction

# Plot the results
plot(X,type='l',col='blue',xlim=c(2175,3000))
abline(v=2540)
lines(prediction,col='red')
lines(forecast$yhat,col='green')
legend('topright',legend=c('Data','AutoSARMA','Prophet')
       ,col=c('blue','red','green'),lty=rep(1,3),cex=0.7)
SE.prophet = (forecast$yhat[2540:2905] - X[2540:2905])^2
SE.FSARMA = (prediction[2540:2905] - X[2540:2905,1])^2
plot(SE.prophet,type='l',col='green')
lines(SE.FSARMA,col='red')
CS.prophet = cumsum(SE.prophet)
CS.FSARMA = cumsum(SE.FSARMA)
plot(CS.prophet,type='l',col='green',ylab='Cumulative error')
lines(CS.FSARMA,col='red')
legend('topleft',legend=c('AutoSARMA','Prophet'),col=c('red','green'),lty=c(1,1))

```

The model is trained using the previous 2540 observation, and predict on the rest of time. From the cumulative error plot, we can see that the error of prophet is almost upper bounding our model. Our model has sastisfactory result.

## Reference
R Core Team (2018). R: A language and environment for statistical computing. R
  Foundation for Statistical Computing, Vienna, Austria. URL
  https://www.R-project.org/.




